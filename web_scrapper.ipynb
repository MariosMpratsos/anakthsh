{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb8c487-9763-46d1-8a0e-cc4b4f1b7ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from inverted_index import create_index\n",
    "\n",
    "# Συνάρτηση για ανάκτηση και επεξεργασία των δεδομένων από τη Wikipedia\n",
    "def fetch_wikipedia_data(url, all_data):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Ανάκτηση του τίτλου (προστασία αν δεν υπάρχει τίτλος)\n",
    "        title_tag = soup.find('h1', id=\"firstHeading\")\n",
    "        title = title_tag.text if title_tag else \"No Title Found\"\n",
    "        \n",
    "        # Ανάκτηση όλων των παραγράφων του άρθρου\n",
    "        paragraphs = soup.find_all('p')\n",
    "        text_content = []\n",
    "        for paragraph in paragraphs:\n",
    "            text_content.append(paragraph.text.strip())\n",
    "        \n",
    "        # Δημιουργία ευρετηρίου για τις λέξεις\n",
    "        # index = create_index(text_content)\n",
    "\n",
    "        # Προσθήκη δεδομένων στο ενιαίο αρχείο\n",
    "        all_data.append({\n",
    "            \"title\": title,\n",
    "            \"content\": text_content,\n",
    "            # \"index\": index  # Αποθήκευση του ευρετηρίου\n",
    "        })\n",
    "        print(f\"Data for {title} added to the collection.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n",
    "\n",
    "# Συνάρτηση για αποθήκευση όλων των δεδομένων σε ένα αρχείο .json\n",
    "def save_data_to_json(name, all_data):\n",
    "    with open(name, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Saving data to {name}\")\n",
    "\n",
    "# Συνάρτηση για να διαβάσει τα URLs από το αρχείο links.txt\n",
    "def read_urls_from_file():\n",
    "    try:\n",
    "        with open('links.txt', 'r') as file:\n",
    "            urls = file.readlines()\n",
    "        # Αφαιρούμε τα κενά και τα \\n από το τέλος κάθε γραμμής\n",
    "        urls = [url.strip() for url in urls]\n",
    "        return urls\n",
    "    except FileNotFoundError:\n",
    "        print(\"File links.txt not found.\")\n",
    "        return []\n",
    "    \n",
    "def from_json_to_str(inp):\n",
    "    documents = list()\n",
    "    for document in inp:\n",
    "        paragraphs = str()\n",
    "        for paragraph in document['content']:\n",
    "            paragraphs = paragraphs + paragraph + '\\n'\n",
    "        documents.append((paragraphs))  \n",
    "    return documents\n",
    "\n",
    "# Κύρια συνάρτηση που ζητάει URLs από τον χρήστη ή διαβάζει από το αρχείο\n",
    "def web_scrapper():\n",
    "    all_data = []  # Λίστα που θα κρατάει όλα τα δεδομένα\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Enter URLs manually.\")\n",
    "    print(\"2. Read URLs from links.txt.\")\n",
    "    print(\"Type 'STOP' to stop the scraping and save the data.\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"Enter your choice (1/2): \").strip()\n",
    "        if choice == '1':\n",
    "            # Εισαγωγή URLs χειροκίνητα\n",
    "            while True:\n",
    "                url = input(\"Enter URL (or type 'STOP' to stop): \")\n",
    "                if url.strip().upper() == 'STOP':\n",
    "                    print(\"Stopping.\")\n",
    "                    return  # Exit the loop for manual URL input\n",
    "                # Ensure the URL starts with 'https://en.wikipedia.org/wiki/'\n",
    "                if not url.startswith('https://en.wikipedia.org/wiki/'):\n",
    "                    print(\"Please enter a valid Wikipedia article URL (starting with 'https://en.wikipedia.org/wiki/').\")\n",
    "                    continue\n",
    "                fetch_wikipedia_data(url, all_data)\n",
    "                # Αποθήκευση όλων των δεδομένων στο τέλος\n",
    "                if all_data:\n",
    "                    print(\"Saving data.\")\n",
    "                    save_data_to_json(\"all_wikipedia_data.json\",all_data)\n",
    "                    save_data_to_json(\"all_wikipedia_index.json\",create_index(from_json_to_str(all_data)))\n",
    "                else:\n",
    "                    print(\"No data to save.\")\n",
    "\n",
    "        \n",
    "        elif choice == '2':\n",
    "            # Ανάγνωση URLs από το αρχείο links.txt\n",
    "            urls = read_urls_from_file()\n",
    "            if not urls:\n",
    "                print(\"No URLs found in links.txt. Please ensure the file exists and contains URLs.\")\n",
    "                break\n",
    "            for url in urls:\n",
    "                fetch_wikipedia_data(url, all_data)\n",
    "                # Αποθήκευση όλων των δεδομένων στο τέλος\n",
    "                if all_data:\n",
    "                    print(\"Saving data.\")\n",
    "                    save_data_to_json(\"all_wikipedia_data.json\",all_data)\n",
    "                    save_data_to_json(\"all_wikipedia_index.json\",create_index(from_json_to_str(all_data)))\n",
    "                else:\n",
    "                    print(\"No data to save.\")\n",
    "\n",
    "        elif choice.strip().upper() == 'STOP':\n",
    "            print(\"Stopping.\")\n",
    "            break  # Exit the loop when 'STOP' is entered\n",
    "        else:\n",
    "            print(\"Invalid choice. Please choose 1 or 2.\")\n",
    "\n",
    "   \n",
    "def main():\n",
    "    web_scrapper();\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
